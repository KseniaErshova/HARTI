{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "RANDOM_STATE = 42  # Pseudo-random state\n",
    "\n",
    "from utils import *\n",
    "sns.set_palette(\"tab10\") # Default seaborn theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Upload dataset\n",
    "#### Download dataset from https://doi.org/10.5281/zenodo.5597750\n",
    "### Use the filename 'vae_data_main'\n",
    "\n",
    "# Reset index\n",
    "vae_data_main = vae_data_main.reset_index(drop=True)\n",
    "\n",
    "# Correct data type\n",
    "vae_data_main.date = pd.to_datetime(vae_data_main.date, format=\"%Y/%m/%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove patients based on exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove patients who were monitored for less than 48 hours\n",
    "\n",
    "print('48 h. Number of patients before: ', len(vae_data_main.ID.unique()))\n",
    "print(\"48 h. Number of ICU admissions before: \", len(vae_data_main.ID_subid.unique()))\n",
    "\n",
    "df_tmp = vae_data_main.copy()\n",
    "tmp = vae_data_main.groupby('ID_subid').count().date == 1\n",
    "ids_w_only_one_row = tmp[tmp == True].index\n",
    "\n",
    "vae_data_main = vae_data_main.loc[\n",
    "    ~((vae_data_main.day_in_icu_max <=1) & vae_data_main.ID_subid.isin(ids_w_only_one_row))]\n",
    "\n",
    "print(\"\\n48 h. Number of patients after: \", len(vae_data_main.ID.unique()))\n",
    "print(\"48 h. Number of ICU admissions after: \", len(vae_data_main.ID_subid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Censore patients' data at day 365 in the ICU if they stayed longer\n",
    "\n",
    "print(\"Censored patients: \", vae_data_main.loc[(vae_data_main.day_in_icu >365)].ID.unique())\n",
    "vae_data_main = vae_data_main.loc[ ~(vae_data_main.day_in_icu >365)]\n",
    "\n",
    "# Set max LOS and ICU LOS at 365 days\n",
    "vae_data_main['los'].where(vae_data_main['los'] < 365, 365, inplace=True)\n",
    "vae_data_main['day_in_icu_max'].where(vae_data_main['day_in_icu_max'] < 365, 365, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove patients who had HARTI present on admission\n",
    "\n",
    "ids_to_drop = (vae_data_main[['ID_subid', 'infection_respiratory']].groupby('ID_subid').first() == 1.)\n",
    "ids_to_drop = ids_to_drop[ids_to_drop.infection_respiratory == True].index\n",
    "vae_data_main = vae_data_main[~vae_data_main.ID_subid.isin(ids_to_drop)]\n",
    "\n",
    "print(\"POA, people remained: \", len(vae_data_main.ID.unique()))\n",
    "print(\"POA, admissions remained: \", len(vae_data_main.ID_subid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove COVID positive patients\n",
    "\n",
    "covid_ids = ['2311/20', '2489/20', '2467/20', '2549/20', '2633/20', '2778/20', '3624/20', '3765/20',\n",
    "             '3859/20', '3976/20', '3977/20', '5386/20', '6045/20', '6213/20', '6471/20', '5287/20',\n",
    "             '6738/20', '7177/20', '6891/20', '7103/20', '7660/20', '7227/20', '6567/20', '7910/20',\n",
    "             '7423/20']\n",
    "\n",
    "vae_data_main = vae_data_main[~vae_data_main.ID.isin(covid_ids)]\n",
    "\n",
    "print('COVID, # of pts, after', len(vae_data_main.ID.unique()))\n",
    "print('COVID, # of admissions, after', len(vae_data_main.ID_subid.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create aggregated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dummies\n",
    "vae_data_main = pd.get_dummies(vae_data_main, columns=['outcome', 'gender', 'disease_type', 'endotracheal_tube'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracheostomy median day\n",
    "\n",
    "values = vae_data_main.loc[vae_data_main['endotracheal_tube_3'] ==\n",
    "                           1.,['ID_subid','date']].groupby('ID_subid').min().reset_index()\n",
    "\n",
    "res = {}\n",
    "i = 0\n",
    "for uid, date in values.values:\n",
    "    query_res = vae_data_main.loc[(vae_data_main.ID_subid == uid) & (vae_data_main.date < date), 'mech_vent']\n",
    "    res[uid] = {\n",
    "        'n_days_with': query_res.sum(), \n",
    "        'n_days_total': query_res.shape[0]}\n",
    "    \n",
    "res = pd.DataFrame.from_dict(res).T.replace(0., np.NaN)\n",
    "res.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write new columns: 'days on mechanical ventilation before tracheostomy' and 'days in ICU before tracheostomy'\n",
    "\n",
    "vae_data_main['days_mech_vent_before_tracheostomy'] = np.NaN\n",
    "vae_data_main['days_before_tracheostomy'] = np.NaN\n",
    "\n",
    "for uid in res.index:\n",
    "    vae_data_main.loc[vae_data_main.ID_subid == uid, 'days_before_tracheostomy'] = res.loc[uid,'n_days_total']\n",
    "    vae_data_main.loc[vae_data_main.ID_subid == uid, 'days_mech_vent_before_tracheostomy'] = res.loc[uid,'n_days_with']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add antibiotics class\n",
    "\n",
    "with open('antibiotics_class.json', 'r') as f:\n",
    "    antibiotics_classes = json.load(f)\n",
    "\n",
    "for col in [\"antibiotic_\" + str(i) for i in range(1,5)]:\n",
    "    vae_data_main[col + '_class'] = vae_data_main[col].replace(antibiotics_classes)\n",
    "    \n",
    "# Add column with antibiotics binary\n",
    "vae_data_main['antibiotics_total_binary']= (vae_data_main.antibiotics_total >=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD: year column\n",
    "vae_data_main['year'] = vae_data_main.date.dt.year\n",
    "\n",
    "# ADD: yearmonth col\n",
    "vae_data_main['yearmonth'] = vae_data_main.date.dt.strftime(\"%y%m\")\n",
    "\n",
    "# ADD: halfyear col\n",
    "halfyear = ((vae_data_main.date.dt.strftime(\"%y\").astype('int') - 11) * 12 + vae_data_main.date.dt.strftime(\"%m\").astype('int')) // 6\n",
    "vae_data_main['halfyear'] = halfyear + 1\n",
    "\n",
    "# ADD first day in the ICU\n",
    "date_series = vae_data_main[['ID_subid', 'date', 'day_in_icu']].groupby('ID_subid').first()\n",
    "date_series = (date_series.date - date_series.day_in_icu.apply(lambda x: np.timedelta64(int(x)-1, 'D')))\n",
    "date_dict = date_series.to_dict()\n",
    "vae_data_main['first_day_in_icu'] = vae_data_main.ID_subid.map(date_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days with factor during each admission\n",
    "\n",
    "cols = [\n",
    "    'mech_vent', 'central_line', 'feeding_tube', 'arterial_line', 'antibiotics_total_binary',\n",
    "    'evd', 'icpm', 'urinary_catheter', 'csfl_ne', 'csfl_ss', 'hypothermia',\n",
    "    'hemodialysis', 'total_parenteral_feeding',\n",
    "    'intestinal_dysfunction', 'convulsions', 'sedation',\n",
    "    'anxiolytics', 'aphasia', 'mutism', 'vasopressors', 'infection_cns', \n",
    "    'infection_bloodstream', 'infection_urinary', 'infection_ssi', 'infection_other',\n",
    "    'endotracheal_tube_0', 'endotracheal_tube_1', 'endotracheal_tube_2', 'endotracheal_tube_3']\n",
    "\n",
    "for col in cols:\n",
    "    n_days = vae_data_main.loc[:, [col, 'ID_subid']].groupby('ID_subid').sum()\n",
    "\n",
    "    # To dict\n",
    "    n_days_dict = n_days.to_dict()[col]\n",
    "    \n",
    "    # Write results\n",
    "    vae_data_main[col + '_days'] = vae_data_main.ID_subid.map(n_days_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surgeries aggregated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count surgeries\n",
    "def agg_func(x):\n",
    "    return len(x.iloc[-1]) if type(x.iloc[-1]) == list else x.iloc[-1]\n",
    "\n",
    "# Surgery name\n",
    "operations = [col for col in vae_data_main.columns \n",
    "              if 'st_' in col \n",
    "              and 'len' not in col \n",
    "              and 'name' not in col\n",
    "              and 'icu' not in col\n",
    "             ]   \n",
    "\n",
    "# All surgeries\n",
    "new_cols = [val + '_count' for val in operations]\n",
    "tmp = vae_data_main.loc[:,['ID_subid'] + operations].copy().groupby('ID_subid').agg(agg_func)\n",
    "for col, new_col in tqdm.tqdm(zip(operations, new_cols)):\n",
    "    vae_data_main.loc[:,new_col] = vae_data_main.ID_subid.apply(lambda x: tmp.loc[x, col] if x in tmp.index else 0)\n",
    "    \n",
    "# Fill na with 0 where appropriate for surgery count\n",
    "vae_data_main[vae_data_main.columns[vae_data_main.columns.str.contains('count')]] = vae_data_main[vae_data_main.columns[vae_data_main.columns.str.contains('count')]].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number (sum) of all surgeries\n",
    "\n",
    "vae_data_main['st_all_sum'] = vae_data_main.loc[:, ('st_device_count', 'st_other_count',\n",
    "                                                    'st_craniotomy_count', 'st_endovascular_count',\n",
    "                                                    'st_endonasal_count', 'st_spinal_count')].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total length of surgeries by type\n",
    "cols = ['st_craniotomy_len', 'st_device_len', 'st_endonasal_len',\n",
    "        'st_endovascular_len', 'st_other_len', 'st_spinal_len']\n",
    "\n",
    "def agg_func(x):\n",
    "    return max(x.apply(lambda l: np.nansum(l) if isinstance(l, list) else -1))\n",
    "\n",
    "for col in cols:\n",
    "    n_days = vae_data_main.loc[:, [col, 'ID_subid']].groupby('ID_subid').agg(agg_func)\n",
    "\n",
    "    # To dict\n",
    "    n_days_dict = n_days.to_dict()[col]\n",
    "    \n",
    "    # Write results\n",
    "    vae_data_main[col + '_sum'] = vae_data_main.ID_subid.map(n_days_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total length of all surgeries\n",
    "vae_data_main['st_all_len_sum'] = vae_data_main.loc[:, ('st_craniotomy_len_sum', 'st_device_len_sum', 'st_endonasal_len_sum',\n",
    "        'st_endovascular_len_sum', 'st_other_len_sum', 'st_spinal_len_sum')].sum(axis=1)\n",
    "\n",
    "vae_data_main.loc[vae_data_main['st_all_len_sum'] < 0, 'st_all_len_sum'] =0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flag infections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add flag HAI\n",
    "\n",
    "infection_cols = vae_data_main.columns[vae_data_main.columns.str.contains('infection_')].tolist()\n",
    "vae_data_main['hai'] = vae_data_main.loc[:, infection_cols].sum(axis=1)\n",
    "\n",
    "# Collect IDs of patients without HAI\n",
    "no_hai_ids = vae_data_main[['hai','ID_subid']].groupby('ID_subid').max() == 0.\n",
    "no_hai_ids = no_hai_ids[no_hai_ids.hai].index\n",
    "\n",
    "print(\"Number of ICU admissions without HAIs: \", len(no_hai_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add HARTI first date\n",
    "vae_data_main.date = pd.to_datetime(vae_data_main.date, format=\"%Y/%m/%d\")\n",
    "\n",
    "vae_data_main['harti_first_date'] = None\n",
    "for id_subid, time in vae_data_main.loc[vae_data_main.infection_respiratory > 0,\n",
    "                                        ['ID_subid', 'date']].groupby('ID_subid').min().reset_index().values:\n",
    "    vae_data_main.loc[vae_data_main.ID_subid == id_subid, 'harti_first_date'] = time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add VAP flag\n",
    "\n",
    "class RollingCondition():\n",
    "    def __init__(self):\n",
    "        self.flag = False\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        if x.iloc[0] == 0:\n",
    "            self.flag = True\n",
    "        \n",
    "        if not self.flag:\n",
    "            return x.iloc[0]\n",
    "        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_res = {}\n",
    "\n",
    "def _agg_inf_respiratory(x):\n",
    "    return x.iloc[0] == 0 and x.iloc[1] == 0 and x.iloc[2] == 1\n",
    "    \n",
    "\n",
    "for uid in vae_data_main.loc[(vae_data_main.infection_respiratory == 1) & (vae_data_main.mech_vent == 1)].ID_subid.unique():\n",
    "    # Finding starting dates\n",
    "    cols = ['mech_vent', 'infection_respiratory', 'date', 'ID_subid']\n",
    "    df = vae_data_main.loc[vae_data_main.ID_subid == uid, cols]\n",
    "    starting_dates = df.loc[(df.rolling(3).mech_vent.sum() == 3.) & \\\n",
    "                            (df.rolling(3).infection_respiratory.agg(_agg_inf_respiratory)),\n",
    "                            'date']\n",
    "    \n",
    "    if len(starting_dates) > 0:\n",
    "        res = {}\n",
    "        for i, date in enumerate(starting_dates):\n",
    "            res[i] = df[df.date >= date].infection_respiratory.rolling(1).agg(RollingCondition())\n",
    "            \n",
    "        meta_res[uid] = pd.DataFrame.from_dict(res).sum(axis=1)\n",
    "        \n",
    "vap_result = pd.DataFrame.from_dict(meta_res).sum(axis=1)\n",
    "\n",
    "# Prepare column \n",
    "vap_result = pd.DataFrame.from_dict(meta_res).sum(axis=1) # was sum\n",
    "vap_result = pd.DataFrame(vap_result, columns=['vap_result'])\n",
    "\n",
    "# Writing column to main data\n",
    "vae_data_main['vap'] = 0.\n",
    "vae_data_main['vap'] = vae_data_main[['vap']].copy().join(vap_result).sum(axis=1).values #was sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add flag for patients with non-VAP respiratory infections\n",
    "a = vae_data_main.loc[(vae_data_main.vap == 0) & (vae_data_main.infection_respiratory > 0)].index\n",
    "vae_data_main['non_vap_resp_hai'] = vae_data_main.index.isin(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add HARTI groups annotation column\n",
    "mask = {\n",
    "    '0000': 'No HAI',\n",
    "    '1011': 'NVA-HARTI',\n",
    "    '1101': 'VA-HARTI',\n",
    "    '0001': 'Other HAI',\n",
    "    '1111': 'Dual HARTI'\n",
    "}\n",
    "def map_label(row):\n",
    "    mask_ = f'{int(row[0])}{int(row[1])}{int(row[2])}{int(bool(row[3]))}'\n",
    "    return mask[mask_]\n",
    "\n",
    "groups = vae_data_main.loc[:, ('ID_subid', 'infection_respiratory', 'vap',\n",
    "                        'non_vap_resp_hai', 'hai')].groupby('ID_subid').max().apply(map_label, axis=1)\n",
    "groups_dict = groups.to_dict()\n",
    "\n",
    "# Map groups by ID_subid\n",
    "vae_data_main['group'] = vae_data_main.ID_subid.map(groups_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new columns with \"days with factors before HARTI = _bid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE CALCULATE VALUES STARTING FROM THE FIRST DAY OF SURVEILLANCE HERE\n",
    "\n",
    "# Columns with binary values\n",
    "# Calculate the number of days with factor before the onset of respiratory HAI\n",
    "# if no respiratory HAI - total number of days with factor\n",
    "\n",
    "cols = [\n",
    "    'mech_vent', 'central_line', 'feeding_tube', 'arterial_line', 'antibiotics_total_binary',\n",
    "    'evd', 'icpm', 'urinary_catheter', 'csfl_ne', 'csfl_ss', 'hypothermia',\n",
    "    'hemodialysis', 'total_parenteral_feeding',\n",
    "    'intestinal_dysfunction', 'convulsions', 'sedation',\n",
    "    'anxiolytics', 'aphasia', 'mutism', 'vasopressors', 'infection_cns', \n",
    "    'infection_bloodstream', 'infection_urinary', 'infection_ssi', 'infection_other',\n",
    "    'endotracheal_tube_0', 'endotracheal_tube_1', 'endotracheal_tube_2', 'endotracheal_tube_3']\n",
    "\n",
    "for col in cols:\n",
    "    n_days = vae_data_main.loc[\n",
    "        vae_data_main.date < vae_data_main.harti_first_date.apply(\n",
    "            lambda x: x if x else np.datetime64('2022-01')), [col, 'ID_subid']].groupby('ID_subid').sum()\n",
    "\n",
    "    # To dict\n",
    "    n_days_dict = n_days.to_dict()[col]\n",
    "    \n",
    "    # Write results\n",
    "    vae_data_main[col + '_bid'] = vae_data_main.ID_subid.map(n_days_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of ICU stay\n",
    "# Max value before the onset of respiratory HAI\n",
    "\n",
    "cols = ['day_in_icu']\n",
    "\n",
    "for col in cols:\n",
    "    n_days = vae_data_main.loc[\n",
    "        vae_data_main.date < vae_data_main.harti_first_date.apply(\n",
    "            lambda x: x if x else np.datetime64('2022-01')), [col, 'ID_subid']].groupby('ID_subid').max()\n",
    "\n",
    "    # To dict\n",
    "    n_days_dict = n_days.to_dict()[col]\n",
    "    \n",
    "    # Write results\n",
    "    vae_data_main[col + '_bid'] = vae_data_main.ID_subid.map(n_days_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE CALCULATE VALUES STARTING FROM THE FIRST DAY OF SURVEILLANCE HERE\n",
    "\n",
    "# Columns with numeric values\n",
    "# Median for five days before the onset of respiratory HAI\n",
    "# if a patient has respiratory HAI from the first day => fill with first day value\n",
    "\n",
    "def median_last_five_values(x):\n",
    "    return np.nanmedian(x[-5:])\n",
    "\n",
    "\n",
    "cols = ['gcs', 'rass', 'pbss', 'charlson', 'antibiotics_total']\n",
    "vae_data_main.gcs = vae_data_main.gcs.astype('float64')\n",
    "\n",
    "for col in cols:\n",
    "    # Fill with zeros\n",
    "    vae_data_main[col + '_bid'] = 0.\n",
    "\n",
    "    # infected\n",
    "    n_days_inf = vae_data_main.loc[\n",
    "        vae_data_main.date < vae_data_main.harti_first_date.apply(\n",
    "            lambda x: x if x else np.datetime64('2000-01')), [col, 'ID_subid']].groupby('ID_subid').agg(median_last_five_values)\n",
    "\n",
    "    # To dict\n",
    "    n_days_inf_dict = n_days_inf.to_dict()[col]\n",
    "    \n",
    "    # not infected\n",
    "    n_days_not_inf = vae_data_main.loc[\n",
    "        vae_data_main.date < vae_data_main.harti_first_date.apply(\n",
    "            lambda x: np.datetime64('2022-01') if (not x) else np.datetime64('2000-01')), [col, 'ID_subid']].groupby('ID_subid').agg(np.nanmedian)\n",
    "    \n",
    "    n_days_not_inf_dict = n_days_not_inf.to_dict()[col]\n",
    "    \n",
    "    # Sum\n",
    "    inf_dict_len = len(n_days_inf_dict)\n",
    "    not_inf_dict_len = len(n_days_not_inf_dict)\n",
    "    \n",
    "    n_days_inf_dict.update(n_days_not_inf_dict)\n",
    "    \n",
    "    assert len(n_days_inf_dict) == inf_dict_len + not_inf_dict_len\n",
    "    \n",
    "    # Write results\n",
    "    vae_data_main[col + '_bid'] = vae_data_main.ID_subid.map(n_days_inf_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surgeries before HARTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with the number of surgeries (by type) before HARTI\n",
    "\n",
    "cols = ['st_craniotomy', 'st_device', 'st_endonasal',\n",
    "        'st_endovascular', 'st_other', 'st_spinal']\n",
    "\n",
    "def func(x):\n",
    "    return x.apply(lambda k: len(k) if isinstance(k, list) else k).max()\n",
    "    \n",
    "for col in cols:\n",
    "    n_days = vae_data_main.loc[\n",
    "        vae_data_main.date < vae_data_main.harti_first_date.apply(\n",
    "            lambda x: x if x else np.datetime64('2022-01')), [col, 'ID_subid']].groupby('ID_subid').agg(func)\n",
    "\n",
    "    # To dict\n",
    "    n_days_dict = n_days.to_dict()[col]\n",
    "    \n",
    "    # Write results\n",
    "    vae_data_main[col + '_bid'] = vae_data_main.ID_subid.map(n_days_dict)\n",
    "    \n",
    "    \n",
    "# Add total length of all surgeries\n",
    "vae_data_main['st_all_sum_bid'] = vae_data_main.loc[:, ('st_craniotomy_bid', 'st_device_bid',\n",
    "                                                        'st_endonasal_bid', 'st_endovascular_bid',\n",
    "                                                        'st_other_bid', 'st_spinal_bid')].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE CALCULATE VALUES STARTING FROM THE FIRST DAY OF SURVEILLANCE HERE\n",
    "\n",
    "# Length of surgeries by type\n",
    "# Summarize all before the onset of HARTI\n",
    "\n",
    "len_cols = ('st_craniotomy_len', 'st_device_len', 'st_endonasal_len',\n",
    "           'st_endovascular_len', 'st_other_len', 'st_spinal_len')\n",
    "\n",
    "def agg_func(x):\n",
    "    return max(x.apply(lambda l: np.nansum(l) if isinstance(l, list) else -1))\n",
    "\n",
    "for col in len_cols:\n",
    "    n_days = vae_data_main.loc[\n",
    "        vae_data_main.date < vae_data_main.harti_first_date.apply(\n",
    "            lambda x: x if x else np.datetime64('2022-01')), [col, 'ID_subid']].groupby('ID_subid').agg(agg_func)\n",
    "\n",
    "    # To dict\n",
    "    n_days_dict = n_days.to_dict()[col]\n",
    "    \n",
    "    # Write results\n",
    "    vae_data_main[col + '_sum_bid'] = vae_data_main.ID_subid.map(n_days_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with sum of length of all surgeries before HARTI\n",
    "len_cols_bid = ('st_craniotomy_len_sum_bid', 'st_device_len_sum_bid', 'st_endonasal_len_sum_bid',\n",
    "           'st_endovascular_len_sum_bid', 'st_other_len_sum_bid', 'st_spinal_len_sum_bid')\n",
    "\n",
    "vae_data_main['st_all_len_sum_bid'] = vae_data_main.loc[:, len_cols_bid].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fillna\n",
    "bid_cols = vae_data_main.columns[vae_data_main.columns.str.contains('_bid')]\n",
    "vae_data_main[bid_cols] = vae_data_main[bid_cols].fillna(0)\n",
    "assert not vae_data_main[bid_cols].isna().max().values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop old surgeries columns and other\n",
    "\n",
    "cols_to_drop = ['outcome_discharged', 'gender_F', 'st_device', 'st_other', 'st_craniotomy',\n",
    "                'st_endovascular', 'st_endonasal', 'st_spinal', 'st_device_len', 'st_other_len',\n",
    "                'st_craniotomy_len', 'st_endovascular_len', 'st_endonasal_len', 'st_spinal_len']\n",
    "\n",
    "vae_data_main = vae_data_main.drop(columns=cols_to_drop)\n",
    "\n",
    "print_info(vae_data_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -1 and 0 with NaN in len columns \n",
    "\n",
    "len_cols = ['st_craniotomy_len_sum', 'st_device_len_sum', 'st_endonasal_len_sum',\n",
    "            'st_endovascular_len_sum', 'st_other_len_sum', 'st_spinal_len_sum',\n",
    "            'st_all_len_sum', 'st_craniotomy_len_sum_bid', 'st_device_len_sum_bid',\n",
    "            'st_endonasal_len_sum_bid', 'st_endovascular_len_sum_bid', 'st_other_len_sum_bid',\n",
    "            'st_spinal_len_sum_bid', 'st_all_len_sum_bid'\n",
    "]\n",
    "\n",
    "for col in len_cols:\n",
    "    vae_data_main[col].replace(-1, np.nan, inplace=True)\n",
    "    vae_data_main[col].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values in analytical dataset\n",
    "\n",
    "# For columns below NaNs are if no surgery of this type\n",
    "# ('st_craniotomy_len_sum', 18808, 0.35),\n",
    "#  ('st_device_len_sum', 38831, 0.72),\n",
    "#  ('st_endonasal_len_sum', 51548, 0.96),\n",
    "#  ('st_endovascular_len_sum', 48221, 0.9),\n",
    "#  ('st_other_len_sum', 47740, 0.89),\n",
    "#  ('st_spinal_len_sum', 52065, 0.97),\n",
    "#  ('st_all_len_sum', 8425, 0.16)\n",
    "\n",
    "[(x,y,z) for x,y,z in zip(vae_data_main.columns, vae_data_main.isnull().values.sum(0),\n",
    "                          round(vae_data_main.isnull().sum(0) / vae_data_main.shape[0], 2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data/'\n",
    "os.makedirs(PATH, exist_ok=True)\n",
    "\n",
    "FILENAME = 'Updated_VAE_Data_Main'\n",
    "TIMESTAMP = datetime.datetime.now().strftime('%y%m%d_%H%M')\n",
    "\n",
    "# CSV\n",
    "os.path\n",
    "vae_data_main.to_csv(os.path.join(PATH, '{}_{}.csv'.format(FILENAME, TIMESTAMP)))\n",
    "\n",
    "# Pickle\n",
    "with open(os.path.join(PATH, '{}_{}.pkl'.format(FILENAME, TIMESTAMP)), 'wb') as f:\n",
    "    pickle.dump(vae_data_main, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
